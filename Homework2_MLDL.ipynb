{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of My Homework2-MLDL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilMowgli/Homework2-Caltech101/blob/master/Copy_of_My_Homework2_MLDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "e901fa41-eb59-4708-9969-9e3e4ceb6a69"
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed torch-1.4.0\n",
            "Collecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torchvision-0.5.0\n",
            "Collecting Pillow-SIMD\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/6a/30d21c886293cca3755b8e55de34137a5068b77eba1c0644d3632080516b/Pillow-SIMD-7.0.0.post3.tar.gz (630kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 4.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow-SIMD\n",
            "  Building wheel for Pillow-SIMD (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow-SIMD: filename=Pillow_SIMD-7.0.0.post3-cp36-cp36m-linux_x86_64.whl size=1110296 sha256=28db1001cfa7fd95bffcc729543d37d14afafc84e6ed3b880c64db8a66b3e5d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/ac/4f/4cdf8febba528e5f1b09fc58d5181e1c12ed1e8655dcd583b8\n",
            "Successfully built Pillow-SIMD\n",
            "Installing collected packages: Pillow-SIMD\n",
            "Successfully installed Pillow-SIMD-7.0.0.post3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from random import sample\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 101 \n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-3           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "9258147c-0c16-41a9-e6ff-ed9f94dbb764"
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/LilMowgli/Homework2-Caltech101.git\n",
        "  !mv 'Homework2-Caltech101' 'Caltech101'\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories'\n",
        "from Caltech101.caltech_dataset import Caltech\n",
        "\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "\n",
        "\n",
        "validation_split = .5 # define portion of validation split\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed) # seed the generator\n",
        "np.random.shuffle(indices) # shuffle indices to get balanced distribution in training and validation set\n",
        "train_indexes, val_indexes = indices[split:], indices[:split] \n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_dataset)))\n",
        "print('Valid Dataset: {}'.format(len(val_dataset)))\n",
        "print('Test Dataset: {}'.format(len(test_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework2-Caltech101'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 9340 (delta 53), reused 0 (delta 0), pack-reused 9256\u001b[K\n",
            "Receiving objects: 100% (9340/9340), 129.50 MiB | 40.50 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "Checking out files: 100% (9150/9150), done.\n",
            "Train Dataset: 2892\n",
            "Valid Dataset: 2892\n",
            "Test Dataset: 2893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbS9OmpcyilX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Caltech101.Manager import Manager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKTya8Yk4VTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function to show an image grid\n",
        "\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOcpzlet6E5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sanity check: visualize a batch of images\n",
        "dataiter = iter(val_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# Show images\n",
        "matplotlib_imshow(img_grid, one_channel=False)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdux0XEs5L5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Train vs Validation loss and Train vs Validation Accuracy\n",
        "\n",
        "def plot_scores(train_loss, validation_loss, train_accuracy, validation_accuracy, save_directory):\n",
        "\n",
        "  # axes[0] = train loss\n",
        "  # axes[1] = train vs validation accuracy\n",
        "  fig, axes = plt.subplots(1, 2, figsize = [15, 5])\n",
        "\n",
        "  axes[0].plot(list(train_loss.keys()), list(train_loss.values()), \n",
        "               color = '#2E84D5', linewidth = 2.5, label = 'Train Loss')\n",
        "  axes[0].plot(list(validation_loss.keys()), list(validation_loss.values()), \n",
        "               color = '#FF9232', linewidth = 2.5, label = 'Validation Loss')\n",
        "  axes[0].set_title(\"Val vs Train Loss\")\n",
        "  axes[0].set_xlabel(\"epoch\")\n",
        "  axes[0].set_ylabel(\"loss\")\n",
        "\n",
        "  axes[1].plot(list(train_accuracy.keys()), list(train_accuracy.values()), \n",
        "               color = '#2E84D5', linewidth = 2.5, label = 'Train Accuracy')\n",
        "  axes[1].plot(list(validation_accuracy.keys()), list(validation_accuracy.values()), \n",
        "               color = '#FF9232', linewidth = 2.5, label = 'Validation Accuracy')\n",
        "  axes[1].set_title(\"Val vs Train Accuracy\")\n",
        "  axes[1].set_xlabel(\"epoch\")\n",
        "  axes[1].set_ylabel(\"accuracy\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  axes[0].legend()\n",
        "  axes[1].legend()\n",
        "  axes[0].grid(True)\n",
        "  axes[1].grid(True)\n",
        "\n",
        "  fig.savefig(save_directory)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1WUbwNmigCM",
        "colab_type": "text"
      },
      "source": [
        "##FMManager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuIRUGRaie24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.backends import cudnn\n",
        "from copy import deepcopy\n",
        "\n",
        "class TemporaryManager():\n",
        "    \"\"\"Manage training, validation and testing of a neural network.\n",
        "    \n",
        "    Args:\n",
        "        device (string): chosen device to run network operations on\n",
        "        criterion: loss function\n",
        "        optimizer: optimization algorithm to change the attributes of the\n",
        "            neural network, e.g., stochastic gradient descent (SGD)\n",
        "        scheduler: learning rate scheduling policy, e.g., MultiStepLR\n",
        "        train_dataloader DataLoader instance of the training set\n",
        "        val_dataloader: DataLoader instance of the validation set\n",
        "        test_dataloader: DataLoader instance of the test set\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device, net, criterion, optimizer, scheduler, train_dataloader, val_dataloader, test_dataloader):\n",
        "        self.device = device\n",
        "\n",
        "        self.net = net\n",
        "        self.best_net = self.net\n",
        "\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "\n",
        "    def set_dataloaders(self, train_dataloader=None, val_dataloader=None, test_dataloader=None):\n",
        "        \"\"\"Update dataloaders.\n",
        "        \n",
        "        Args:\n",
        "            train_dataloader, val_dataloader, test_dataloader: if not None,\n",
        "                update the respective dataloader.\n",
        "        \"\"\"\n",
        "\n",
        "        if train_dataloader is not None:\n",
        "            self.train_dataloader = train_dataloader\n",
        "\n",
        "        if val_dataloader is not None:\n",
        "            self.val_dataloader = val_dataloader\n",
        "        \n",
        "        if test_dataloader is not None:\n",
        "            self.test_dataloader = test_dataloader\n",
        "\n",
        "    # @todo: do we already initialize to 100 output nodes, as in the iCaRL paper?\n",
        "    # if so, is increment_classes needed?\n",
        "    def increment_classes(self, n=10):\n",
        "        \"\"\"Add n classes in the final fully connected layer.\"\"\"\n",
        "\n",
        "        in_features = self.net.fc.in_features  # size of each input sample\n",
        "        out_features = self.net.fc.out_features  # size of each output sample\n",
        "        weight = self.net.fc.weight.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features+n)\n",
        "        self.net.fc.weight.data[:out_features] = weight\n",
        "    \n",
        "    def output_neurons_count(self):\n",
        "        \"\"\"Return the number of output neurons of the current network.\"\"\"\n",
        "\n",
        "        return self.net.fc.out_features\n",
        "\n",
        "    def to_onehot(self, targets): \n",
        "      '''\n",
        "      Args:\n",
        "      targets : dataloader.dataset.targets of the new task images\n",
        "      '''\n",
        "      one_hot_targets = torch.eye(NUM_CLASSES)[targets]\n",
        "\n",
        "      return one_hot_targets.to(self.device)\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        \"\"\"Train the network for a specified number of epochs, and save\n",
        "        the best performing model on the validation set.\n",
        "        \n",
        "        Args:\n",
        "            num_epochs (int): number of epochs for training the network.\n",
        "        Returns:\n",
        "            train_loss: loss computed on the last epoch\n",
        "            train_accuracy: accuracy computed on the last epoch\n",
        "            val_loss: average loss on the validation set of the last epoch\n",
        "            val_accuracy: accuracy on the validation set of the last epoch\n",
        "        \"\"\"\n",
        "\n",
        "        # @todo: is the return behaviour intended? (scores of the last epoch)\n",
        "\n",
        "        self.net.to(self.device)\n",
        "        cudnn.benchmark  # Calling this optimizes runtime\n",
        "\n",
        "        self.best_accuracy = 0 # @todo: should we use best_loss instead?\n",
        "        self.best_epoch = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Run an epoch (start counting form 1)\n",
        "            train_loss, train_accuracy = self.do_epoch(epoch+1)\n",
        "        \n",
        "            # Validate after each epoch \n",
        "            val_loss, val_accuracy = self.validate()    \n",
        "\n",
        "            # Best validation model\n",
        "            if val_accuracy > self.best_accuracy:\n",
        "                self.best_accuracy = val_accuracy\n",
        "                self.best_net = deepcopy(self.net)\n",
        "                self.best_epoch = epoch\n",
        "                print(\"Best model updated\")\n",
        "\n",
        "            print(\"\")\n",
        "\n",
        "        return (train_loss, train_accuracy,\n",
        "                val_loss, val_accuracy)\n",
        "    \n",
        "    def do_epoch(self, current_epoch):\n",
        "        \"\"\"Trains model for one epoch.\n",
        "        \n",
        "        Args:\n",
        "            current_epoch (int): current epoch number (begins from 1)\n",
        "        Returns:\n",
        "            train_loss: average training loss over all batches of the\n",
        "                current epoch.\n",
        "            train_accuracy: training accuracy of the current epoch over\n",
        "                all samples.\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train()  # Set network in training mode\n",
        "\n",
        "        running_train_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")\n",
        "\n",
        "        for images, labels in self.train_dataloader:\n",
        "            loss, corrects = self.do_batch(images, labels)\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_corrects += corrects\n",
        "            total += labels.size(0)\n",
        "            batch_idx += 1\n",
        "\n",
        "        self.scheduler.step()\n",
        "\n",
        "        # Calculate average scores\n",
        "        train_loss = running_train_loss / batch_idx # Average over all batches\n",
        "        train_accuracy = running_corrects / float(total) # Average over all samples\n",
        "\n",
        "        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
        "\n",
        "        return (train_loss, train_accuracy)\n",
        "\n",
        "    def do_batch(self, batch, labels):\n",
        "        \"\"\"Trains model for one batch.\n",
        "        \n",
        "        Args:\n",
        "            batch: batch of images for the model to train.\n",
        "            labels: labels of the batch of images.\n",
        "        \n",
        "        Returns:\n",
        "            loss: loss function computed on the network outputs of the\n",
        "                forward pass.\n",
        "            running_corrects: number of correctly classified images.\n",
        "        \"\"\"\n",
        "\n",
        "        batch = batch.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        # Zero-ing the gradients\n",
        "        self.optimizer.zero_grad() \n",
        "\n",
        "        # One hot encoding of new task labels \n",
        "        one_hot_labels = self.to_onehot(labels) # Size = [128, 10]\n",
        "\n",
        "        # New net forward pass\n",
        "        outputs = self.net(batch)  \n",
        "        \n",
        "        loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Compute the number of correctly classified images\n",
        "        running_corrects = \\\n",
        "            torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        # Backward pass: computes gradients\n",
        "        loss.backward()  \n",
        "\n",
        "        # Update weights based on accumulated gradients\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return (loss, running_corrects)\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Validate the model.\n",
        "        \n",
        "        Returns:\n",
        "            val_loss: average loss function computed on the network outputs\n",
        "                of the validation set (val_dataloader).\n",
        "            val_accuracy: accuracy computed on the validation set.\n",
        "        \"\"\"\n",
        "\n",
        "        self.net.train(False)\n",
        "\n",
        "        running_val_loss = 0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        batch_idx = 0\n",
        "\n",
        "        for images, labels in self.val_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # One hot encoding of new task labels \n",
        "            one_hot_labels = self.to_onehot(labels) # Size = [128, 10]\n",
        "            # New net forward pass\n",
        "            outputs = self.net(images)  \n",
        "            loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update the number of correctly classified validation samples\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calcuate scores\n",
        "        val_loss = running_val_loss / batch_idx\n",
        "        val_accuracy = running_corrects / float(total)\n",
        "\n",
        "        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
        "\n",
        "        return (val_loss, val_accuracy)\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Test the model.\n",
        "        Returns:\n",
        "            accuracy (float): accuracy of the model on the test set\n",
        "        \"\"\"\n",
        "\n",
        "        self.best_net.train(False)  # Set Network to evaluation mode\n",
        "\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "\n",
        "        all_preds = torch.tensor([]) # to store all predictions\n",
        "        all_preds = all_preds.type(torch.LongTensor)\n",
        "        \n",
        "        for images, labels in self.test_dataloader:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = self.best_net(images)\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Update Corrects\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Append batch predictions\n",
        "            all_preds = torch.cat(\n",
        "                (all_preds.to(self.device), preds.to(self.device)), dim=0\n",
        "            )\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = running_corrects / float(total)  \n",
        "\n",
        "        print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "        return (accuracy, all_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGji-PE4imjZ",
        "colab_type": "text"
      },
      "source": [
        "## FMLOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7iSMp0YhWtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Provo anche come distillation\n",
        "\n",
        "class FMLoss(nn.Module):\n",
        "\n",
        "  def __init__(self, weight = None, reduction = 'mean'):\n",
        "    super(FMLoss, self).__init__()\n",
        "\n",
        "  def forward(self, outputs, targets, beta = 0):\n",
        "    EPS = 1e-10\n",
        "    sigmoid= nn.Sigmoid()\n",
        "    loss = torch.mean(-targets*torch.log(sigmoid(outputs)+EPS)\\\n",
        "                        + beta*(1-targets)* torch.pow(sigmoid(outputs), 2))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBwh_OR9MGk",
        "colab_type": "text"
      },
      "source": [
        "**2A. Tuning LR, step_size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl0pQG7FXVjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "739d6a68-a65a-444f-e60c-af20ae9bb860"
      },
      "source": [
        "train_loss = []\n",
        "validation_loss=[]\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "lr = 0.2\n",
        "step_size = 50\n",
        "num_epochs = 60\n",
        "\n",
        "#define network\n",
        "net = alexnet() # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = FMLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = TemporaryManager(DEVICE, net, criterion, optimizer, scheduler,\n",
        "                        train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(num_epochs) \n",
        "\n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "\n",
        "train_loss.append(training_loss)\n",
        "validation_loss.append(val_loss)\n",
        "train_accuracy.append(training_accuracy)\n",
        "validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.006863799454136329, Train accuracy: 0.005326704545454545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "Traceback (most recent call last):\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "AssertionError: can only join a child process\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.006857875967398286, Validation accuracy: 0.007607192254495159\n",
            "Best model updated\n",
            "\n",
            "Epoch: 2, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    self._shutdown_workers()\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "    w.join()\n",
            "AssertionError: can only join a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    self._shutdown_workers()\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.006849730598994277, Train accuracy: 0.009943181818181818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.006838845554739237, Validation accuracy: 0.007607192254495159\n",
            "\n",
            "Epoch: 3, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.006830105431039225, Train accuracy: 0.049360795454545456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "    self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "    w.join()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    w.join()\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.006817463164528211, Validation accuracy: 0.09923928077455048\n",
            "Best model updated\n",
            "\n",
            "Epoch: 4, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    self._shutdown_workers()\n",
            "    w.join()\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    w.join()\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.0068089076402512464, Train accuracy: 0.08700284090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    w.join()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "AssertionError: can only join a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.006795661019471784, Validation accuracy: 0.09923928077455048\n",
            "\n",
            "Epoch: 5, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.0067881816490129995, Train accuracy: 0.08309659090909091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.0067736535565927625, Validation accuracy: 0.09854771784232365\n",
            "\n",
            "Epoch: 6, LR: [0.2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "Traceback (most recent call last):\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f924c2122b0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c5113b9e4a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                         train_dataloader, val_dataloader, test_dataloader)\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-9ed27dd8688b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# Run an epoch (start counting form 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# Validate after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-9ed27dd8688b>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(self, current_epoch)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WhNA49F7qk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NROOn7S8vZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#product allows to make cartesian product between lists of hyperparameters\n",
        "lr_values = [1e-3, 5e-3, 1e-2, 5e-2] # lr value for tuning\n",
        "\n",
        "# lr = 1e-1 diverges\n",
        "parameters = dict(lr = lr_values,\n",
        "                  step_size = [30, 50],\n",
        "                  num_epochs = [50]) \n",
        "\n",
        "param_values = [value for value in parameters.values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHL42RCMALO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "validation_loss=[]\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr, step_size, num_epochs in product(*param_values): # grid search over cartesian products of hyper parameters\n",
        "\n",
        "  #define network\n",
        "  net = alexnet() # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "  \n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(training_loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ_xBq9ls2ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr, step_size, epochs in product(*param_values):\n",
        "  combinations.append([lr, step_size, epochs])\n",
        "\n",
        "for i, comb in enumerate(combinations):\n",
        "  name = 'lr{}_step{}.jpg'.format(comb[0], comb[1])\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i], validation_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsS960TYxB8X",
        "colab_type": "text"
      },
      "source": [
        "**Tuning number of epochs**\n",
        "\n",
        "Try if increasing the number of epochs, performance gets better, or if instead we have an asymptotic behaviour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_kxYBtSwyow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = dict(lr = [1e-2],\n",
        "                  step_size = [40, 50],\n",
        "                  num_epochs = [60, 70]) \n",
        "\n",
        "param_values = [value for value in parameters.values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSsaDRS3xAXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "validation_loss = []\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr, step_size, num_epochs in product(*param_values): # grid search over cartesian products of hyper parameters\n",
        "\n",
        "  #define network\n",
        "  net = alexnet() # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEfFNZe4iTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr, step_size, epochs in product(*param_values):\n",
        "  combinations.append([lr, step_size, epochs])\n",
        "\n",
        "for i, comb in enumerate(combinations):\n",
        "  name = 'lr{}_step{}_epochs{}.jpg'.format(comb[0], comb[1], comb[2])\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIhAH4n0gU_",
        "colab_type": "text"
      },
      "source": [
        "**Tuned Hyper Parameters** \n",
        "1. lr = 1e-2\n",
        "2. step_size = 50\n",
        "3. num_epochs = 50\n",
        "\n",
        "<br>\n",
        "\n",
        "**Train a Model with Tuned Hyper Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fGPEhDL1La5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train model with best hyperparameters found after validation\n",
        "\n",
        "net = alexnet() # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "# best parameters\n",
        "lr = 1e-2\n",
        "step_size = 50\n",
        "num_epochs = 50\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                        train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "net = manager.train(optimizer, scheduler, num_epochs, validation = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwBZfBQQkok3",
        "colab_type": "text"
      },
      "source": [
        "**Test the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhaslcnfXW_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test() # test trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWAb1V0Z58Er",
        "colab_type": "text"
      },
      "source": [
        "**2B. Tuning LR with Adam optimizer** <br>\n",
        "Tune the learning rate using a different optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mt7ldKb4Mv",
        "colab_type": "text"
      },
      "source": [
        "**Training and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njRNqkfAb4aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_values = [1e-3, 5e-3, 1e-2, 5e-2] # lr values for tuning\n",
        "step_size = 50\n",
        "num_epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_lhHUK556vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = []\n",
        "validation_loss = []\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr in lr_values: # grid search over cartesian products of hyper parameters\n",
        "\n",
        "  #define network\n",
        "  net = alexnet() # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob6haODLdx-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr in lr_values:\n",
        "  combinations.append([lr])\n",
        "\n",
        "for i, comb in enumerate(lr_values):\n",
        "  name = 'lr{}_Adam.jpg'.format(comb)\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i], validation_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJwVTPlfLpyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Try larger step_size and number of epochs\n",
        "\n",
        "lr = 1e-2\n",
        "step_size = 55\n",
        "num_epochs = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjGBZgljMLvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define network\n",
        "net = alexnet() # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwW8DYgGMb7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = 'step_size55_epochs60' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiSkZERT819F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeUpUpfx8hls",
        "colab_type": "text"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVjNuOU8gm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test() #test last model trained with lr = 0.01, epochs = 60, step size = 55"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni35rt4Nkwwp",
        "colab_type": "text"
      },
      "source": [
        "<br><br>\n",
        "**3. TRANSFER LEARNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPYb5ZaLDqN0",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk6GxU02DcP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]) # Normalizes tensor with mean and standard deviation required by \n",
        "                                                            # pre-trained models\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                                    \n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNf08TiwETtO",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrHhDDZXD2Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/LilMowgli/Homework2-Caltech101.git\n",
        "  !mv 'Homework2-Caltech101' 'Caltech101'\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories'\n",
        "from Caltech101.caltech_dataset import Caltech\n",
        "\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "validation_split = .5\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indexes, val_indexes = indices[split:], indices[:split]\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFfSJsWUEkZ0",
        "colab_type": "text"
      },
      "source": [
        "**Prepare DataLoaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT8KBUKEEXlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH4bSTK_H4-V",
        "colab_type": "text"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iUg_xkGH3dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed = 100\n",
        "np.random.seed(random_seed)\n",
        "r = np.random.uniform(-3, -1, size = 8)  # randomly sample exponents from a range \n",
        "                                  # [-3, -1) (sample lr from a log scale)\n",
        "lr_values = [10**exp for exp in r] \n",
        "\n",
        "s = np.arange(start = -3, stop = 1, dtype = float) # integer exponents range [-8, 0]\n",
        "eps = [10**expo for expo in s] \n",
        "\n",
        "parameters = [dict(lr = lr_values, #find best batch size and lr\n",
        "                  batch_size = [128, 256, 512], # allows exploring new lr values\n",
        "                  step_size = [5],\n",
        "                  epochs = [7]), \n",
        "              dict(lr = [1e-2], # optimize step_size and num_epochs\n",
        "                   step_size = [5, 7], epochs = [5, 7, 10]),  #7 vs 7, 10\n",
        "              dict(lr = [1e-2, 1e-3], # optimize learning rate and eps for Adam optimizer\n",
        "                   step_size = [5], \n",
        "                   epochs = [7], \n",
        "                   eps = eps)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpKlP3CrakZa",
        "colab_type": "text"
      },
      "source": [
        "**Tuning 1**\n",
        "- Best with lr circa 0.01, batch size 256. <br>\n",
        "  Altre considerazioni su documents\n",
        "\n",
        "**Tuning2**\n",
        "- Best with lr = 1e-2, epochs = 10 (comparable results) step = 5 <br>\n",
        "\n",
        "**Tuning 3 Adam**\n",
        "- Comparable performance to SGD for eps = 0.1\n",
        "- Fino a eps = 0.01 la loss non scende o peggio diverge (spiegare perche ==> eps a denominatore, per probabilita troppo certe, divergenza)\n",
        "- Per eps = 0.1 si hanno risultati comparabili con SGD. Il training avviene molto piu in fretta (2 epochs). Accuracy 1% piu bass. Dipende dalle necessita, se volessi accuracy al massimo opterei per SGD, altrimenti adam risulta piu veloce. Visto che questo è un esercizio per sperimentare, Non ci sono criteri epr esprimere una preferenza quindi rimango sul default SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZjMfz5LuGUt",
        "colab_type": "text"
      },
      "source": [
        "**Lr, Batch Size Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CwgW-ah7jEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_values = [value for value in parameters[0].values()]\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr, batch_size, step_size, num_epochs in product(*param_values):\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "  val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "  #define network\n",
        "  net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "  \n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey3Eg-fUHNcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr, batch_size, step_size, epochs in product(*param_values):\n",
        "  combinations.append([lr, batch_size, step_size, epochs])\n",
        "\n",
        "for i, comb in enumerate(combinations):\n",
        "  name = 'lr{}_batch_size{}_step{}_epochs{}.jpg'.format(comb[0], comb[1], comb[2], comb[3])\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m19nK3AxuAE6",
        "colab_type": "text"
      },
      "source": [
        "**Lr, Step, Epochs Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMnCxCwQQZgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_values = [value for value in parameters[1].values()] #tune step_size and epochs\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr, step_size, num_epochs in product(*param_values): \n",
        "\n",
        "  #define network\n",
        "  net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "  \n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0sQrImZOFA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr, step_size, epochs in product(*param_values):\n",
        "  combinations.append([lr, step_size, epochs])\n",
        "\n",
        "for i, comb in enumerate(lr_values):\n",
        "  name = 'lr{}_Adam.jpg'.format(comb)\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i],  validation_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQM-RDVIt2LD",
        "colab_type": "text"
      },
      "source": [
        "**Adam Optimizer, LR and Epsilon Tuning**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X42MzoQTEc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_values = [value for value in parameters[2].values()] #tune step_size and epochs\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "for lr, step_size, num_epochs, eps in product(*param_values): \n",
        "\n",
        "  #define network\n",
        "  net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "  net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "  #prepare network\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  parameters_to_optimize = net.parameters()\n",
        "  optimizer = optim.Adam(parameters_to_optimize, lr=lr, eps=eps, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "  \n",
        "  manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "  scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "  training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "  \n",
        "  train_loss.append(loss)\n",
        "  validation_loss.append(val_loss)\n",
        "  train_accuracy.append(training_accuracy)\n",
        "  validation_accuracy.append(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5NaWpbHTeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinations = []\n",
        "for lr, step_size, epochs, eps in product(*param_values):\n",
        "  combinations.append([lr, step_size, epochs, eps])\n",
        "\n",
        "for i, comb in enumerate(combinations):\n",
        "  name = 'lr{}_eps{}Adam.jpg'.format(comb[0], comb[-1])\n",
        "  print(name)\n",
        "  plot_scores(train_loss[i], validation_loss[i], train_accuracy[i], validation_accuracy[i], save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK-vIPFceG9e",
        "colab_type": "text"
      },
      "source": [
        "**Train Validated Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tkhRPylnHQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best parmeters learned (batch size kept at default 256)\n",
        "lr = 1e-2\n",
        "num_epochs = 10\n",
        "step_size = 5\n",
        "\n",
        "\n",
        "net = alexnet(pretrained = True)\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "net = manager.train(optimizer, scheduler, num_epochs, validation = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftTUICjRI4OO",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfHRhZMkI3cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ9uxkO9Nzsf",
        "colab_type": "text"
      },
      "source": [
        "**Freeze Convolutional Layers**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntobdP50JSY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best parmeters learned (lower number of epochs)\n",
        "lr = 1e-2\n",
        "num_epochs = 7\n",
        "step_size = 5\n",
        "\n",
        "\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model with \n",
        "\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer\n",
        "                                                 # The convolutional layer is nn.Conv2d\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "#freeze convolution weights\n",
        "for param in net.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "parameters_to_update = []\n",
        "\n",
        "# sanity check freezed parameters\n",
        "for name, param in net.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    parameters_to_update.append(param)\n",
        "  print(\"\\t\",name, param.requires_grad) #False for freezed layer\n",
        "\n",
        "parameters_to_optimize = net.parameters()\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "\n",
        "freezeConvAccuracy = val_accuracy[num_epochs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4LZFzO8jvOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'freezed_CNN.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhcoG5n26s5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(freezeConvAccuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy9Acaiz6kdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyB9VK-2xJcn",
        "colab_type": "text"
      },
      "source": [
        "**Freeze FC Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YteFAUc2xH2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best lr learned. Increase epochs and step size\n",
        "lr = 1e-2\n",
        "num_epochs = 40\n",
        "step_size = 20\n",
        "\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model with \n",
        "\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer\n",
        "                                                 # The convolutional layer is nn.Conv2d\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "#freeze FC weights\n",
        "for param in net.classifier.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "parameters_to_update = []\n",
        "\n",
        "# sanity check freezed parameters\n",
        "for name, param in net.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    parameters_to_update.append(param)\n",
        "  print(\"\\t\",name, param.requires_grad) #False for freezed layer\n",
        "\n",
        "parameters_to_optimize = net.parameters()\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)       \n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores\n",
        "\n",
        "freezeFCAccuracy = val_accuracy[num_epochs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA7R6cEAlDzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'freezed_CNN.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxwg3Mu7Q1MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGhdfhcGbxgs",
        "colab_type": "text"
      },
      "source": [
        "**Conclusions freezed layers**\n",
        "\n",
        "FC freezed works really poorly respect to convolutional layers freezed. This is due to the fact that they share same semantic on the input whille different one on the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCVjnNZW_HF1",
        "colab_type": "text"
      },
      "source": [
        "**4. DATA AUGMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVWWyT59hGr5",
        "colab_type": "text"
      },
      "source": [
        "**TRANSFORMATIONS SET 1**\n",
        "\n",
        "1. CenterCrop\n",
        "2. RandomHoriziontalFlip(p=0.1)\n",
        "3. ColorJitter brightness = 0.5\n",
        "\n",
        "con num_epochs = 13, step_size = 6 Accuracy = 0.85\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWqvajEeDxyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/LilMowgli/Homework2-Caltech101.git\n",
        "  !mv 'Homework2-Caltech101' 'Caltech101'\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories'\n",
        "from Caltech101.caltech_dataset import Caltech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlY641vbBmvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      \n",
        "                                      transforms.CenterCrop(224), \n",
        "                                      transforms.RandomHorizontalFlip(p=0.1), \n",
        "                                      transforms.ColorJitter(brightness = 0.5), \n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]) \n",
        "])\n",
        "\n",
        "#Transformations for validation dataset\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                                    \n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "\n",
        "\n",
        "validation_split = .5\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indexes, val_indexes = indices[split:], indices[:split]\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "#Define dataloader object to iterate over datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkCo6TEgXYst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best hyper parmeters learned (batch size kept at default 256)\n",
        "#Come consigliato nella spiegazione, occorre aumentare training epochs o learning rate\n",
        "lr = 1e-2\n",
        "num_epochs = 14\n",
        "step_size = 7\n",
        "\n",
        "\n",
        "#define network\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPPtpZczt6A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'DA1_CNN.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn3ZouzV4kaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-386Uxskhg8b",
        "colab_type": "text"
      },
      "source": [
        "**TENCROP**<br>\n",
        "\n",
        "1. CenterCrop\n",
        "2. RandomHoriziontalFlip(p=0.1)\n",
        "3. ColorJitter(brightness = 0.5)\n",
        "4. TenCrop on Validation\n",
        "\n",
        "Can not run due to memory issues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ7B-lAF7Ynr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/LilMowgli/Homework2-Caltech101.git\n",
        "  !mv 'Homework2-Caltech101' 'Caltech101'\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories'\n",
        "from Caltech101.caltech_dataset import Caltech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYs7jP9-XZXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      \n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(p=0.1),\n",
        "                                      transforms.ColorJitter(brightness = 0.5), \n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]) \n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.TenCrop(224),\n",
        "                                      transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                      transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225])(crop) for crop in crops]))                                 \n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "#create dataset with defined transformaions\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "validation_split = .5\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indexes, val_indexes = indices[split:], indices[:split]\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "batch_size = 12 # larger values leads to out of memory errors\n",
        "\n",
        "#Define dataloader object to iterate over datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baiXhlI8lyRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_tencrops(model, test_dataloader): \n",
        "\n",
        "  #torch.cuda.ipc_collect()\n",
        "\n",
        "  model = model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  model.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(test_dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    bs, ncrops, c, h, w = images.size()\n",
        "    outputs = model(images.view(-1, c, h, w)) # fuse batch size and ncrops\n",
        "    outputs_avg = outputs.view(bs, ncrops, -1).mean(1) # avg over \n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs_avg.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "  print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCWGaddCDKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best hyper parmeters learned (batch size kept at default 256)\n",
        "#Come consigliato nella spiegazione, occrre aumentare training epochs o learning rate\n",
        "lr = 1e-3\n",
        "num_epochs = 13\n",
        "step_size = 7\n",
        "\n",
        "#define network\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "net = manager.train(optimizer, scheduler, num_epochs, validation = False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgsCmPX5mLUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tencrops(net, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7tpTFoqh9VW",
        "colab_type": "text"
      },
      "source": [
        "**TRANSFORMATIONS SET 2**\n",
        "1. CenterCrop\n",
        "2. RandomHorizontalFlip\n",
        "3. RandomVerticalFlip with lower probability\n",
        "4. Random Perspective\n",
        "\n",
        "Accuracy = 0.81\n",
        "\n",
        "\n",
        "\n",
        "using RandomGrayScale with p =0.1 and dropping random perspective\n",
        "Accuracy = 0.84 senza vertical, \n",
        "0.83 with vertical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mZf_XyM8Eto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Caltech101'):\n",
        "  !git clone https://github.com/LilMowgli/Homework2-Caltech101.git\n",
        "  !mv 'Homework2-Caltech101' 'Caltech101'\n",
        "\n",
        "DATA_DIR = 'Caltech101/101_ObjectCategories'\n",
        "from Caltech101.caltech_dataset import Caltech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-mTiyt9i6JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      \n",
        "                                      transforms.CenterCrop(224),  \n",
        "                                      transforms.RandomHorizontalFlip(p=0.1),\n",
        "                                      transforms.RandomVerticalFlip(p = 0.05),\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "                                 transforms.RandomErasing(p = 0.1)\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  #Remember: AlexNet needs a 224x224 input!\n",
        "                                      transforms.RandomHorizontalFlip(p=0.1),\n",
        "                                      transforms.RandomVerticalFlip(p = 0.05),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), # Normalizes tensor with mean and standard deviation\n",
        "                                 transforms.RandomErasing(p = 0.1)\n",
        "])\n",
        "\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                                    \n",
        "])\n",
        "\n",
        "\n",
        "#create dataset with defined transformaions\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "validation_split = .5\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indexes, val_indexes = indices[split:], indices[:split]\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "\n",
        "#Define dataloader object to iterate over datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyQKqGU0kXxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best hyper parmeters learned (batch size kept at default 256)\n",
        "#Come consigliato nella spiegazione, occrre aumentare training epochs o learning rate\n",
        "lr = 1e-2\n",
        "num_epochs = 11\n",
        "step_size = 8\n",
        "\n",
        "#define network\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HljLylxwPGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'DA2_CNN.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cixJ00v4ZoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcOtMWYnGOOU",
        "colab_type": "text"
      },
      "source": [
        "**TRANSFORMATIONS SET 3**\n",
        "1. RandomCrop\n",
        "2. Horizontal\n",
        "3. VerticalFlip\n",
        "4. RandomPespective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO3LajxVfDvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      \n",
        "                                      transforms.RandomCrop(224), \n",
        "                                      transforms.RandomHorizontalFlip(p=0.1),\n",
        "                                      transforms.RandomPerspective(p = 0.2),\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]), \n",
        "])\n",
        "\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])                                    \n",
        "])\n",
        "\n",
        "\n",
        "#create dataset with defined transformaions\n",
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "validation_split = .5\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed)\n",
        "np.random.shuffle(indices)\n",
        "train_indexes, val_indexes = indices[split:], indices[:split]\n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "\n",
        "#Define dataloader object to iterate over datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp6ZxTRWgEyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Best hyper parmeters learned (batch size kept at default 256)\n",
        "# It is necessary to have larger numnber of  epochs for convergence\n",
        "lr = 1e-2\n",
        "num_epochs = 14\n",
        "step_size = 10\n",
        "\n",
        "#define network\n",
        "net = alexnet(pretrained = True) # Loading AlexNet model\n",
        "net.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#prepare network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "parameters_to_optimize = net.parameters()\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibyi_BsNwYQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'DA3_CNN.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZuEVVZHwZoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZinWkYmlGyl",
        "colab_type": "text"
      },
      "source": [
        "**5. RESNET**\n",
        "\n",
        "Compare Resnet18 and Alexnet performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEOltHZRlTZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models import resnet18, resnet34"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPCfcT1TlcQL",
        "colab_type": "text"
      },
      "source": [
        "**Define and Train the Network**\n",
        "\n",
        "Pretarined weights on ImageNet are loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HS4bnS9lipx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best parmeters learned (lower number of epochs)\n",
        "lr = 1e-2\n",
        "num_epochs = 10\n",
        "step_size = 7\n",
        "\n",
        "resnet = resnet34(pretrained = True) # Loading ResNet model with \n",
        "\n",
        "resnet.fc.out_features = NUM_CLASSES # nn.Linear in pytorch is a fully connected layer\n",
        "                                                 # The convolutional layer is nn.Conv2d\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "parameters_to_optimize = resnet.parameters() # optimize over all parameters\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwofx5zhmV-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'resnet18.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QIdp36tweLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUH5pW9e4LaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Caltech(DATA_DIR, split='train',  transform=train_transform)\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "\n",
        "validation_split = .5 # define portion of validation split\n",
        "random_seed= 42\n",
        "len_dataset = len(train_dataset)\n",
        "indices = list(range(len_dataset))\n",
        "split = int(np.floor(validation_split * len_dataset))\n",
        "np.random.seed(random_seed) # seed the generator\n",
        "np.random.shuffle(indices) # shuffle indices to get balanced distribution in training and validation set\n",
        "train_indexes, val_indexes = indices[split:], indices[:split] \n",
        "\n",
        "val_dataset = Subset(train_dataset, val_indexes)\n",
        "train_dataset = Subset(train_dataset, train_indexes)\n",
        "\n",
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50PmzETA38nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best parmeters learned (lower number of epochs)\n",
        "lr = 1e-2\n",
        "num_epochs = 6\n",
        "step_size = 6\n",
        "\n",
        "resnet = resnet34(pretrained = True) # Loading ResNet model with \n",
        "\n",
        "resnet.fc.out_features = NUM_CLASSES # nn.Linear in pytorch is a fully connected layer\n",
        "                                                 # The convolutional layer is nn.Conv2d\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "parameters_to_optimize = resnet.parameters() # optimize over all parameters\n",
        "\n",
        "# SGD optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=GAMMA)\n",
        "manager = Manager(DEVICE, net, criterion,\n",
        "                          train_dataloader, val_dataloader, test_dataloader)\n",
        "\n",
        "scores = manager.train(optimizer, scheduler, num_epochs) \n",
        "training_loss, training_accuracy, val_loss, val_accuracy = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeDmTKNC5Non",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'resnet34.jpg'\n",
        "plot_scores(training_loss, val_loss, training_accuracy, val_accuracy, save_directory = name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OfQeZFG5RDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manager.test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
